# ============================================
# Yahoo Finance Data Collection Service
# Environment Configuration Template
# ============================================
# 
# INSTRUCTIONS:
# 1. Copy this file to .env: cp .env.example .env
# 2. Edit .env with your actual values
# 3. Never commit .env to version control (it's in .gitignore)
# 4. Run: python validate_config.py to verify your configuration
#
# ============================================

# ============================================
# General Configuration
# ============================================
# Timezone for data processing (use UTC for consistency)
TZ=UTC

# Logging level: DEBUG, INFO, WARNING, ERROR
# Use INFO for normal operation, DEBUG for troubleshooting
LOG_LEVEL=INFO

# Base folder for data storage (relative to project root or absolute path)
BASE_FOLDER=all_ohclv_data

# ============================================
# Local PostgreSQL Database (Optional)
# ============================================
# Set to true to enable local PostgreSQL database uploads
# Requires: DB_NAME, DB_USER, DB_PASSWORD
ENABLE_LOCAL_DB=false

# PostgreSQL connection settings
# Required if ENABLE_LOCAL_DB=true
DB_NAME=your_database
DB_USER=your_user
DB_PASSWORD=your_password
DB_HOST=localhost
DB_PORT=5432

# Example for remote database:
# DB_HOST=your-db-host.example.com
# DB_PORT=5432

# ============================================
# Google Cloud BigQuery (Optional)
# ============================================
# Set to true to enable BigQuery table uploads
# Requires: daily_datset_bq and/or intraday_dataset_bq
ENABLE_BIGQUERY=false

# BigQuery table IDs (format: project.dataset.table)
# At least one should be set if ENABLE_BIGQUERY=true
daily_datset_bq=your-project.your_dataset.daily_table
intraday_dataset_bq=your-project.your_dataset.intraday_table

# Path to Google Cloud service account JSON key file
# Required for BigQuery and GCS uploads
# Can be absolute path or relative to project root
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Example:
# GOOGLE_APPLICATION_CREDENTIALS=/home/user/gcp-credentials.json
# or
# GOOGLE_APPLICATION_CREDENTIALS=./credentials/service-account.json

# ============================================
# Google Cloud Storage - Parquet Files (Optional)
# ============================================
# Storage mode: bigquery, parquet, or both
# - bigquery: Only upload to BigQuery tables
# - parquet: Only upload Parquet files to GCS
# - both: Upload to both BigQuery and GCS
STORAGE_MODE=bigquery

# Set to true to enable GCS Parquet file uploads
# Requires: GCS_BUCKET_NAME
ENABLE_GCS=false

# GCS bucket name (without gs:// prefix)
GCS_BUCKET_NAME=your-bucket-name

# GCS bucket path prefix (where files will be stored)
# Files will be stored as: gs://bucket-name/data/YYYY/MM/DD/ticker_timeframe.parquet
GCS_BUCKET_PATH=data

# Example:
# GCS_BUCKET_NAME=my-finance-data-bucket
# GCS_BUCKET_PATH=yahoo-finance/ohlcv

# ============================================
# Data Quality Monitoring (Optional)
# ============================================
# Set to true to enable automated data quality checks
# Generates HTML reports with visual charts
ENABLE_QUALITY_CHECKS=true

# Path where quality reports will be saved
# Can be relative to project root or absolute path
QUALITY_REPORT_PATH=logs/quality_reports

# Example:
# QUALITY_REPORT_PATH=logs/quality_reports
# or
# QUALITY_REPORT_PATH=/var/log/yfin/quality_reports

# ============================================
# Configuration Examples
# ============================================

# Example 1: Local data collection only (no uploads)
# ENABLE_LOCAL_DB=false
# ENABLE_BIGQUERY=false
# ENABLE_GCS=false
# ENABLE_QUALITY_CHECKS=true

# Example 2: Local PostgreSQL only
# ENABLE_LOCAL_DB=true
# DB_NAME=yfin_data
# DB_USER=postgres
# DB_PASSWORD=your_secure_password
# DB_HOST=localhost
# DB_PORT=5432
# ENABLE_BIGQUERY=false
# ENABLE_GCS=false

# Example 3: BigQuery only
# ENABLE_LOCAL_DB=false
# ENABLE_BIGQUERY=true
# daily_datset_bq=my-project.finance_data.daily_ohlcv
# intraday_dataset_bq=my-project.finance_data.intraday_ohlcv
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
# ENABLE_GCS=false

# Example 4: GCS Parquet only
# ENABLE_LOCAL_DB=false
# ENABLE_BIGQUERY=false
# STORAGE_MODE=parquet
# ENABLE_GCS=true
# GCS_BUCKET_NAME=my-finance-data
# GCS_BUCKET_PATH=data
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# Example 5: All storage options enabled
# ENABLE_LOCAL_DB=true
# DB_NAME=yfin_data
# DB_USER=postgres
# DB_PASSWORD=your_password
# ENABLE_BIGQUERY=true
# daily_datset_bq=my-project.finance_data.daily_ohlcv
# intraday_dataset_bq=my-project.finance_data.intraday_ohlcv
# STORAGE_MODE=both
# ENABLE_GCS=true
# GCS_BUCKET_NAME=my-finance-data
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
# ENABLE_QUALITY_CHECKS=true

# ============================================
# Notes
# ============================================
# - At least one storage option should be enabled for data persistence
# - Quality checks are recommended but optional
# - All paths can be relative to project root or absolute
# - For GCP services, ensure the service account has appropriate permissions:
#   - BigQuery: BigQuery Data Editor, BigQuery Job User
#   - GCS: Storage Object Creator, Storage Object Viewer
# - The service will skip uploads if credentials are not configured
# - Check logs/ directory for detailed execution logs
# - Run python validate_config.py to verify your configuration
